                                # Streamlit Word Autocomplete App Using GPT-2

#Generate real-time next-word suggestions for partial user input leveraging a cached GPT-2 text generation pipeline.

# This Streamlit application uses the Hugging Face transformers library to provide word autocomplete suggestions. It loads a cached GPT-2 model pipeline for text generation, or creates and caches it if not already saved. Given a partial sentence typed by the user, the app generates multiple continuation sequences and extracts likely next words to suggest. The UI displays these suggestions dynamically with a styled background.



# Streamlit Word Autocomplete with GPT-2 and Model Caching
import streamlit as st
from transformers import pipeline, set_seed
import joblib
import os
# This code implements a word autocomplete web app using Streamlit and the Hugging Face GPT-2 text generation model. It efficiently caches the loaded model using joblib to avoid repeated downloads and loading times. Users can type a partial sentence, and the app generates possible next word suggestions based on GPT-2‚Äôs predictions, enhancing typing speed and creativity.



MODEL_PATH = "cached_gpt2_model.pkl"
# This variable defines the filename used to save or load the cached GPT-2 text generation model. By storing the model locally in a pickle (.pkl) file, the app avoids reloading the model from scratch every time it runs, which speeds up initialization and improves efficiency.



# Efficient GPT-2 Text Generation Model Loading with Caching
def load_or_cache_generator():
    if os.path.exists(MODEL_PATH):
        # Load from file (pickled model)
        generator = joblib.load(MODEL_PATH)
    else:
        # Create and save the model
        generator = pipeline("text-generation", model="gpt2")
        joblib.dump(generator, MODEL_PATH)
    return generator

generator = load_or_cache_generator()
# This function loads a GPT-2 text generation pipeline either from a cached pickle file (cached_gpt2_model.pkl) if it exists, or initializes a new pipeline and saves it for future use. This caching mechanism improves performance by avoiding repeated model downloads and setup during multiple runs.



# GPT-2 Based Autocomplete Suggestions Generator
def get_autocomplete_suggestions(partial_text, max_suggestions=5):
    if not partial_text.strip():
        return []

    set_seed(42)
    outputs = generator(
        partial_text,
        max_length=len(partial_text.split()) + 5,
        num_return_sequences=max_suggestions,
        do_sample=True,
        top_k=50,
        top_p=0.95,
        temperature=1.0,
        eos_token_id=50256,
    )
    
    suggestions = set()
    for output in outputs:
        generated_text = output['generated_text']
        continuation = generated_text[len(partial_text):].strip()
        if continuation:
            first_word = continuation.split(' ')[0]
            # filter out punctuation or empty tokens
            if first_word.isalpha():
                suggestions.add(first_word)
    return list(suggestions)
# This function generates autocomplete suggestions using a GPT-2 text generation model. Given a partial input text, it predicts likely next words by sampling multiple sequences, filtering out punctuation and duplicates, and returns a list of relevant word suggestions to enhance user input completion.



# Streamlit UI
st.title("üìù  Word Autocomplete ")



# Interactive Autocomplete Interface with GPT-2 in Streamlit
user_input = st.text_input("Type a sentence:")

if user_input:
    with st.spinner("Generating suggestions..."):
        suggestions = get_autocomplete_suggestions(user_input)
    if suggestions:
        st.markdown("### Suggestions:")
        for s in suggestions:
            st.write(f"- {s}")
        top_suggestion = suggestions[0] if suggestions else ""
        if top_suggestion:
            st.markdown(f"**Preview:** `{user_input} {top_suggestion}`")
    else:
        st.write("No suggestions found.")
else:
    st.write("Loading Suggestions")
# This Streamlit UI allows users to type a sentence and receive autocomplete suggestions generated by a GPT-2 language model. As the user inputs text, the app displays a list of possible next words, with a preview of the top suggestion appended to the input, enhancing the text composition experience in real time.



# Custom Background Styling for Streamlit App
page_element = """
    <style>
[data-testid="stAppViewContainer"]{
  background-image: url("https://img.freepik.com/free-vector/realistic-white-golden-geometric-background_79603-2032.jpg?ga=GA1.1.704494411.1747992680&semt=ais_hybrid&w=740");
  background-size: cover;
}
[data-testid = 'stHeader']{
  background-color: rgba(0,0,0,0);
}
</style>
"""

st.markdown(page_element, unsafe_allow_html= True)
# This code snippet applies custom CSS styling to the Streamlit app, setting a visually appealing white and golden geometric background image for the main app container. It also makes the header transparent, creating a sleek, modern look for the user interface while maintaining readability and focus on the content.



# Conclusion
#This app combines modern transformer models with Streamlit‚Äôs interactive UI for a simple yet effective autocomplete experience. By caching the model pipeline, it optimizes load times and makes text generation responsive enough for real-time use cases like typing assistance, content creation, or educational tools.